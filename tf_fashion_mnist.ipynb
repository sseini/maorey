{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test)= fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full.shape:  (60000, 28, 28)\n",
      "y_train_full.shape:  (60000,)\n",
      "X_test.shape:  (10000, 28, 28)\n",
      "y_test.shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_full.shape: \", X_train_full.shape)\n",
    "print(\"y_train_full.shape: \", y_train_full.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=list(set(y_train_full))\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[\"T-short/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUK0lEQVR4nO3da2ycVXoH8P8z43HGcXyJ4+AYExISwiWUEsCE0GVX7KbLkmzVgCohaIXoNqpXXZBARVUp/bC0Hyq03YuQdrVtuGhDtQtCy2aBXboQIqSAKCEOhFy45SKnSUici+vYsWN7PPP0g1+QAZ/nmHln5p1w/j/Jsj2PX8/x2H/P5XnPOaKqIKIvv1TSAyCiymDYiQLBsBMFgmEnCgTDThSImkpeWa3M0CzqK3mVQRi9oM5ZE7GPTZ+y/98X0vbx0jhu1mek3fX8B3n7m9MXNoIhjOnolL/1WGEXkZsAPAwgDeBRVX3I+vos6nGtrIxzldXJl6gytzf3/9syZ01SBfPY2b+3//mOtNg/W3rlSbN+YcsJZ+3U9faxsVm/ly9py3mLbnLWin4YLyJpAD8DsArAUgC3i8jSYr8fEZVXnOfsywHsVdX9qjoG4CkAa0ozLCIqtThh7wBwcNLnh6LLPkVEukSkW0S6cxiNcXVEFEfZX41X1XWq2qmqnRnMKPfVEZFDnLAfBjB/0ufnRZcRURWKE/atAJaIyAUiUgvgNgDPlWZYRFRqRbfeVHVcRO4G8CImWm+Pq+ruko3sbBKzjVNz3ude6viU+qdGzPrm83/qrA2q3TrLXGeP3W7cARlP13HEuP58j33wXz10n1mf+x//Y195jN+L1NjR0HH7/IJqFKvPrqovAHihRGMhojLi6bJEgWDYiQLBsBMFgmEnCgTDThQIhp0oEFLJ1WUbpUUTm+Jaxmmoo6uvMetL/2WnWX+g7WWz/kGuyaxvGbrQWbu2fq95rE9/Pt76A5fU9jprrw67xw0AfzbrA7O+a2yOWf+H/1zrrJ3776+bx56ttugmDGjflH/svGcnCgTDThQIhp0oEAw7USAYdqJAMOxEgQin9RbTkb//E2ftX//uCfPYjNjTIX3trazkzPrRcXdr7hsz7fbVhoEr7etO2dd9z2y7tffqiHti5b6xc8xj61P2MmZ5z33VJbVHnLWn+5ebx263bxa/hFYcZuuNiBh2olAw7ESBYNiJAsGwEwWCYScKBMNOFIiKbtl8Nvvh9x5x1j4an20emxF7a+K8Z7nnHOx9k+fVnHLWtowsNI/dM2z3upfO+sisPz/caNbfHl7grM1MjZnHDqfsHYRSYi90/frwEmdtVeMO89itf/ods555eZtZr0a8ZycKBMNOFAiGnSgQDDtRIBh2okAw7ESBYNiJAsE+eySVzZr1gzn3ssW+edW+PntH5v/Mek6L/zVlPb3sKxoOmvW/bLR34X71TLtZ76h1/2y1nnn+Pg0peyvrj3Lu8x/ysM9t6LnFvs2X2Kt/l22+ehyxwi4iPQAGAeQBjKtqZykGRUSlV4p79q+r6okSfB8iKiM+ZycKRNywK4CXRGSbiHRN9QUi0iUi3SLSnYO9phgRlU/ch/HXq+phETkHwEYReV9VN0/+AlVdB2AdMLHgZMzrI6IixbpnV9XD0ftjADYAsJfsJKLEFB12EakXkYaPPwZwI4BdpRoYEZVWnIfxbQA2yMT62DUAfqWqfyjJqBJwetUVZn1x7ZvO2vujnl5zjd1H/23/VWa9qeaMWV/V4J6bfSzfYB57edbus28fbTbr1pr1ANCcHjZqQ+axvz15tVm/bNZhs26d3zBYqDOPveP618z6G8iY9WpUdNhVdT8AOyFEVDXYeiMKBMNOFAiGnSgQDDtRIBh2okBwimvk0Cp7WeLmlN3+inPsWyfmm/VZtfZpxn/e+LazlvYst5xX+/+9b5nsNOzvP1RwLwdtbakMAHsHWs26zw3N7ztrIwW7dXZb01az/gbcW3hXK96zEwWCYScKBMNOFAiGnSgQDDtRIBh2okAw7ESBYJ89kp1tL0scx5DaPd0fLPm1Wd/m2Xb5dwPLnLXWzKB57CUz7C2ZF9UeM+v7x+wtn60prs/024sR373gFbO+xDO2rWcWOmu+8w/25Owef037PLM+fuSoWU8C79mJAsGwEwWCYScKBMNOFAiGnSgQDDtRIBh2okCwzx5pmGn32a1e+cyUPd98fo271wwAO8fsnu5iTz95Sa27p/u20WsGgKdP2vt6XNe4z6z7tk1OGfPd9w/bP/fsjL3U9Ffr7PnwV2cPOGtvjlxgHttR02/WT3eeb9azz7PPTkQJYdiJAsGwEwWCYScKBMNOFAiGnSgQDDtRINhnj3z93D1mPR/j/2Jb2r12OgA0Ze0tnTecXmDWra2JO2fuN49tz9jXvfvMeWa9pcbuhV9R97/OWke23zz2qroes35w3F4nYG56zFmrlXHz2KxxmwLA4a+lzfri581yIrx/wSLyuIgcE5Fdky5rEZGNIrInem/vJEBEiZvO3dUvANz0mcvuB7BJVZcA2BR9TkRVzBt2Vd0MoO8zF68BsD76eD2Am0s7LCIqtWKfs7ep6scnJh8F0Ob6QhHpAtAFAFnMLPLqiCiu2K/Gq6oCUKO+TlU7VbUzA/uFKiIqn2LD3isi7QAQvbenZRFR4ooN+3MA7ow+vhPAs6UZDhGVi/c5u4g8CeAGAK0icgjA9wE8BOBpEVkL4ACAW8s5yEq4sXGnWR829hlfUeeeNw0Al/zhHrP+7MqfmvVrjHnZANBj7KHen683j21M2/PRl9fbffo8xKxv6LvKWSt49oZfmjll1r+9fa1Zn1vvPgfgnxa+YB47pHY0Gi/+7GvW1c8bdlW93VFaWeKxEFEZ8XRZokAw7ESBYNiJAsGwEwWCYScKBKe4Ri72tHleOzPfWWvzTNW8aG23Wd/wjrs9BQD3ztlm1vfl3P+z6z3LXI94tpM+Pt5g1lfU2a25h/vcTZu+Qbst2NRRa9ZHts4x6z0zWpy1zovt5b1fG2ky6/dd/LJZfwLuv5ek8J6dKBAMO1EgGHaiQDDsRIFg2IkCwbATBYJhJwpEMH32dLPdN60Ve6rmQKHOWcvAXlbY5/eHLjPrvWONZn1l07vOWq1nSeQxtcc+t2bQrPcbtwsArJjb46w1ttvTaz/MORdAAgDM3W4vB12/171M9qy/yZrHnszPMuvfmuleIhtgn52IEsSwEwWCYScKBMNOFAiGnSgQDDtRIBh2okAE02cfvfpCs/7GyFyzbm3xm4Pdy/Y5cdzuo//FJVvN+tHxZmcto3Yv2rfUdEHt8w8aUmfs759zb/m1qO64eWxrOmd/70X2n2/2eXsbbkvfuN1n3zVmz/OvmW9vdT1+8NAXHlNcvGcnCgTDThQIhp0oEAw7USAYdqJAMOxEgWDYiQIRTJ+971L3lsuAf311y5YRu0/uc8eVb5j1hTX2mvb7xtqcNd/P1ZGxtx7uGbPPP+ioGTDrO0+2O2sX1feaxw4W7Puiwavt+fDzzKptRsru8c/03K7919l99lnV2GcXkcdF5JiI7Jp02YMiclhEtkdvq8s7TCKKazoP438B4KYpLv+Jqi6L3uyd7Ykocd6wq+pmAPZjPSKqenFeoLtbRHZED/Nnu75IRLpEpFtEunMo/nkxEcVTbNh/DmAxgGUAjgD4kesLVXWdqnaqamcG9otkRFQ+RYVdVXtVNa+qBQCPAFhe2mERUakVFXYRmdxPuQXALtfXElF18PbZReRJADcAaBWRQwC+D+AGEVkGQAH0APhu+YZYGuP28uaolzGzPmQ8BRn0rJ3us6phh1k/OF58H3+oYD91ak7b8907Mu611wEgD3u+eybtnuuf8axpP+jZO371pbvNujWbfVTtPnqjZ56+z3CrfT9qz5YvD2/YVfX2KS5+rAxjIaIy4umyRIFg2IkCwbATBYJhJwoEw04UiGCmuObtHXqxoMZutZwsuJdcfqn/Us+126cJX1prt/1+Pdjh+f5uaRTM+mDebhv6pnL6ZGvcrb1Wz/TYd0ftn/v+tk1mfa181Vl79NQi89jLswfN+sUZu2WZizfruSx4z04UCIadKBAMO1EgGHaiQDDsRIFg2IkCwbATBSKYPvvoHLvf7HN57Qln7cHeBeaxha45Zj2DN836sGeaakvNaWctJfbP3Ziyl2MeKNgnKGQ8ffyhsVpnLetZrvmjnHO1MwBATs0yRr59jbO28fgB89gV5+/zXLf9c481ewaXAN6zEwWCYScKBMNOFAiGnSgQDDtRIBh2okAw7ESBCKbPXmi05x/bixrb/xX7B2aax2ZX2Vsu7xhLm3XfnPKRgnvJ5bzYSz0X1P5/7+vTbxlZaNZvmf+Os3bcs0S2b2w7x84x6ye+M+Ss5c+41ycAgDTsPnlOPfUm319U5fGenSgQDDtRIBh2okAw7ESBYNiJAsGwEwWCYScKRDB99tmtg2Z9sGD/3/so3+CsScruRa+96HWzviJr99mzYs+9nplyn0MwXLB/xScL9jkCeU+v29cL3zvs7oXfP+9F89iTnnn8y2fYWzo/2nrSWTt62v37BIABta+7DfZcfNTGWz+hHLz37CIyX0ReEZF3RWS3iNwTXd4iIhtFZE/03l5pgIgSNZ2H8eMA7lPVpQBWALhLRJYCuB/AJlVdAmBT9DkRVSlv2FX1iKq+FX08COA9AB0A1gBYH33ZegA3l2mMRFQCX+g5u4gsBHAlgC0A2lT1SFQ6CqDNcUwXgC4AyMJ+fkhE5TPtV+NFZBaAZwDcq6qf2pFPVRWYeuaAqq5T1U5V7czAftGDiMpnWmEXkQwmgv5LVf1NdHGviLRH9XYAx8ozRCIqBe/DeBERAI8BeE9Vfzyp9ByAOwE8FL1/tiwjLJFFs91tGAA45WnzNBhLLueG3cslA8B/X9Zs1tff9T2zPnyuZzrlee4psE3Nw+axdyy2l7G+qq7HrO8dnfLZ2yfeOubedvmb791jHtvwtv07mbfFvYQ2AOCNHc5S36/mmYdmxW6tfeDbk9meWZyI6Txn/wqAOwDsFJHt0WUPYCLkT4vIWgAHANxalhESUUl4w66qr8H9f2plaYdDROXC02WJAsGwEwWCYScKBMNOFAiGnSgQwUxxbcjYyzEfHrcn7S3MuLds9uxa7HXOz+wpsOX0Iux+8Yv441jfvxUfGrXk5M/Yf/r1Yi893q/2qd9ScxZOcSWiLweGnSgQDDtRIBh2okAw7ESBYNiJAsGwEwUimD57rmAv15z2bE2cMeqpwXg3o8zwrOBTsOez67gx99qztXCiPNtJS429VLSkPctcj7jXIMgetNcgSPm2bIb999Tc7N4uOim8ZycKBMNOFAiGnSgQDDtRIBh2okAw7ESBYNiJAhFMn72gdk93pGD3dEfU3Vet7Y/5P9PXR8+Nxfv+Fk+vOzarz+85B8D7c6eK32GocZ993b59BAbzdWZ9RsaeD58E3rMTBYJhJwoEw04UCIadKBAMO1EgGHaiQDDsRIGYzv7s8wE8AaANgAJYp6oPi8iDAP4WwPHoSx9Q1RfKNdC4Cp4Ns+fWDNj1lHvdec9UeK9UXdas58vZZ6/m+e4ekrbnlFs/WTpn/9xNxu8bALIpe//2pbN7zfohs1oe0zmpZhzAfar6log0ANgmIhuj2k9U9YflGx4Rlcp09mc/AuBI9PGgiLwHoKPcAyOi0vpCz9lFZCGAKwFsiS66W0R2iMjjIjLl/kki0iUi3SLSnYP90IiIymfaYReRWQCeAXCvqg4A+DmAxQCWYeKe/0dTHaeq61S1U1U7Myj+XGYiimdaYReRDCaC/ktV/Q0AqGqvquZVtQDgEQDLyzdMIorLG3YREQCPAXhPVX886fL2SV92C4BdpR8eEZXKdF6N/wqAOwDsFJHt0WUPALhdRJZhosPRA+C7ZRhfyXQfON+sN2WKf2BS1xuvfaXj1Tcd8myg+XzRx9YO2sduGLjSrOeMKc8AcGio2TOC05566U3n1fjXgCmb1FXbUyeiz+MZdESBYNiJAsGwEwWCYScKBMNOFAiGnSgQohWc4tgoLXqtrKzY9Z01fMs5n8XTUKmytugmDGjflH9QvGcnCgTDThQIhp0oEAw7USAYdqJAMOxEgWDYiQJR0T67iBwHcGDSRa0ATlRsAF9MtY6tWscFcGzFKuXYFqjq3KkKFQ37565cpFtVOxMbgKFax1at4wI4tmJVamx8GE8UCIadKBBJh31dwtdvqdaxVeu4AI6tWBUZW6LP2YmocpK+ZyeiCmHYiQKRSNhF5CYR+UBE9orI/UmMwUVEekRkp4hsF5HuhMfyuIgcE5Fdky5rEZGNIrInej/lHnsJje1BETkc3XbbRWR1QmObLyKviMi7IrJbRO6JLk/0tjPGVZHbreLP2UUkDeBDAN/ExDbVWwHcrqrvVnQgDiLSA6BTVRM/AUNEvoaJ3QSeUNU/ii77AYA+VX0o+kc5W1X/sUrG9iCA00lv4x3tVtQ+eZtxADcD+GskeNsZ47oVFbjdkrhnXw5gr6ruV9UxAE8BWJPAOKqeqm4G0PeZi9cAWB99vB4TfywV5xhbVVDVI6r6VvTxIICPtxlP9LYzxlURSYS9A8DBSZ8fQnXt964AXhKRbSLSlfRgptCmqkeij48CaEtyMFPwbuNdSZ/ZZrxqbrtitj+Piy/Qfd71qnoVgFUA7ooerlYlnXgOVk2902lt410pU2wz/okkb7titz+PK4mwHwYwf9Ln50WXVQVVPRy9PwZgA6pvK+rej3fQjd4fS3g8n6imbbyn2mYcVXDbJbn9eRJh3wpgiYhcICK1AG4D8FwC4/gcEamPXjiBiNQDuBHVtxX1cwDujD6+E8CzCY7lU6plG2/XNuNI+LZLfPtzVa34G4DVmHhFfh+Af05iDI5xLQLwTvS2O+mxAXgSEw/rcph4bWMtgDkANgHYA+BlAC1VNLb/ArATwA5MBKs9obFdj4mH6DsAbI/eVid92xnjqsjtxtNliQLBF+iIAsGwEwWCYScKBMNOFAiGnSgQDDtRIBh2okD8Px0mBHn6xrJyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classes = list(set(fashion_mnist.target))\n",
    "i=9\n",
    "plt.imshow(X_train[i])\n",
    "plt.show()\n",
    "classes[y_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "    tf.keras.layers.Dense(units=300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=10, activation=\"softmax\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7fcef46c6f10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcef46c6430>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcef4ad7400>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcef446f070>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1=model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 flatten_1\n",
      "1 dense_3\n",
      "2 dense_4\n",
      "3 dense_5\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(\"{} {}\".format(i, model.layers[i].name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_layer('dense') is hidden1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_3/kernel:0' shape=(784, 300) dtype=float32, numpy=\n",
       "array([[ 0.01892646,  0.01864656, -0.03602036, ...,  0.04582755,\n",
       "        -0.01670528, -0.0722525 ],\n",
       "       [-0.00420896, -0.0532738 , -0.01371464, ...,  0.00780462,\n",
       "         0.06376866, -0.02828711],\n",
       "       [-0.03010641,  0.02356788, -0.04034908, ..., -0.04123152,\n",
       "        -0.02991709,  0.05629347],\n",
       "       ...,\n",
       "       [-0.00542358, -0.05504116, -0.05181821, ..., -0.02548859,\n",
       "         0.06682433, -0.03399598],\n",
       "       [-0.02956246,  0.05544956, -0.05401129, ...,  0.02394639,\n",
       "        -0.02799995,  0.008151  ],\n",
       "       [-0.04163796,  0.04194717, -0.05393902, ...,  0.03392109,\n",
       "        -0.07177073,  0.05369541]], dtype=float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_3/bias:0' shape=(300,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden2=model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2, biases2 = hidden2.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_4/kernel:0' shape=(300, 100) dtype=float32, numpy=\n",
       "array([[ 0.09584986, -0.04975961,  0.10267314, ..., -0.04760934,\n",
       "        -0.03126795,  0.08305544],\n",
       "       [-0.05525433, -0.01252107, -0.08863692, ...,  0.04186992,\n",
       "         0.00491206, -0.07647793],\n",
       "       [-0.01118198,  0.08815063,  0.02141408, ...,  0.00851154,\n",
       "        -0.10467778,  0.07597715],\n",
       "       ...,\n",
       "       [ 0.03737132, -0.01648532, -0.06646863, ..., -0.10455751,\n",
       "        -0.11460675, -0.00557595],\n",
       "       [ 0.07339325, -0.06817474, -0.06667951, ..., -0.03841624,\n",
       "        -0.04538452, -0.01058177],\n",
       "       [-0.08945347, -0.06351784, -0.05206257, ..., -0.03880385,\n",
       "         0.04876887, -0.04637501]], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_4/bias:0' shape=(100,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights3, biases3= output.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_5/kernel:0' shape=(100, 10) dtype=float32, numpy=\n",
       "array([[-0.1866777 , -0.21613584, -0.19644332, -0.22912203,  0.20724285,\n",
       "         0.10453287,  0.04141492,  0.04843611, -0.17263567,  0.0519402 ],\n",
       "       [-0.09326899,  0.18160623, -0.04616955, -0.00618361,  0.09000638,\n",
       "         0.19281062, -0.08850674,  0.03007501, -0.10025315,  0.04454663],\n",
       "       [-0.03744236,  0.17726406, -0.22657722, -0.04384764, -0.21751855,\n",
       "        -0.18477464,  0.19060093,  0.20250064, -0.08121239,  0.12472308],\n",
       "       [ 0.10644823,  0.09758845, -0.1008646 ,  0.07671505,  0.05026585,\n",
       "         0.18437457, -0.21767981, -0.19823056,  0.11360365,  0.03725737],\n",
       "       [ 0.16482446, -0.07813503,  0.15454379,  0.11455917,  0.15375677,\n",
       "        -0.12872717,  0.20200098, -0.03513271,  0.02515039, -0.18968433],\n",
       "       [-0.15499303, -0.04941639,  0.1358997 ,  0.08119729,  0.10830709,\n",
       "        -0.12045301, -0.18310967,  0.14871633,  0.2026282 ,  0.11984876],\n",
       "       [-0.17168722, -0.19407418, -0.16614096, -0.05785081,  0.19171178,\n",
       "        -0.19865073, -0.1009749 , -0.02266972,  0.1644932 , -0.08119595],\n",
       "       [-0.04708424,  0.19764015,  0.06138882,  0.153308  , -0.22318715,\n",
       "         0.06003478,  0.15400833,  0.15057513, -0.03277203,  0.21520048],\n",
       "       [-0.04963212, -0.09932977,  0.13094845, -0.00213966,  0.14811265,\n",
       "        -0.151086  ,  0.00899112, -0.00566208, -0.06791689,  0.02406341],\n",
       "       [ 0.22627246,  0.22539657, -0.11050621,  0.12785065, -0.04167485,\n",
       "        -0.10019714,  0.05930567, -0.22241189, -0.15123479, -0.02633296],\n",
       "       [ 0.19482544,  0.12788558, -0.13953465,  0.07758817, -0.04530106,\n",
       "        -0.14507964,  0.0651381 , -0.03577183, -0.15529433,  0.15145451],\n",
       "       [ 0.21971947,  0.02090269,  0.16537717, -0.14363584, -0.03467242,\n",
       "         0.21783516, -0.08609396, -0.19173919, -0.01164089,  0.11003646],\n",
       "       [-0.0947448 ,  0.13625884,  0.1779078 , -0.16914544,  0.07165423,\n",
       "         0.09110433, -0.15841779,  0.23005962, -0.05516858, -0.0516167 ],\n",
       "       [ 0.21234402, -0.03069475,  0.13231122, -0.06958413,  0.09783843,\n",
       "        -0.06791627,  0.10138023,  0.11722547, -0.12821266, -0.00763558],\n",
       "       [ 0.1856812 ,  0.1942311 ,  0.02568343, -0.1685642 , -0.06151083,\n",
       "         0.2292153 , -0.20238364, -0.10318907,  0.19498771, -0.01961024],\n",
       "       [-0.14101319, -0.10148591, -0.05399685,  0.23287627, -0.21213272,\n",
       "        -0.14760083,  0.06121108, -0.06797601,  0.09764871,  0.05185434],\n",
       "       [-0.20089987,  0.14117962, -0.2081857 ,  0.07538304, -0.17177387,\n",
       "         0.12760684,  0.00320153,  0.11321205, -0.18517098,  0.18685567],\n",
       "       [ 0.1448093 ,  0.21420205,  0.10337433,  0.22947395, -0.07441399,\n",
       "        -0.03806016,  0.0909062 , -0.140367  ,  0.20196113,  0.13667428],\n",
       "       [-0.14482054, -0.19295713, -0.07782097, -0.19149926,  0.14259925,\n",
       "         0.16560915,  0.20547184,  0.06144735,  0.04719996,  0.1228056 ],\n",
       "       [ 0.03984311,  0.22679576, -0.1164746 , -0.0631426 ,  0.09666291,\n",
       "        -0.1907649 , -0.15825531,  0.18806654,  0.20772031,  0.01114437],\n",
       "       [ 0.04569203,  0.07668209,  0.0759384 , -0.05030872,  0.13927183,\n",
       "         0.10773355,  0.20884755,  0.14105701,  0.22029373, -0.18952698],\n",
       "       [-0.17356528, -0.100256  ,  0.226457  , -0.06651434, -0.00707726,\n",
       "        -0.08418243, -0.00330926,  0.0052928 ,  0.03207207,  0.21935916],\n",
       "       [ 0.01468071,  0.168623  , -0.12689482, -0.01631901, -0.21432589,\n",
       "         0.1146892 ,  0.04334745,  0.08125731, -0.19575001,  0.0285171 ],\n",
       "       [ 0.05149353,  0.17592585, -0.18655097, -0.08522643, -0.0690954 ,\n",
       "        -0.04805657, -0.02870464, -0.01498631, -0.15080285, -0.08386226],\n",
       "       [ 0.06906867,  0.10428402, -0.12891242, -0.0063476 ,  0.1909633 ,\n",
       "         0.2306818 ,  0.10412249,  0.09133863,  0.19785246,  0.05104762],\n",
       "       [-0.00316945, -0.09871008,  0.06045264,  0.06456524, -0.03294845,\n",
       "        -0.07259545,  0.19617894,  0.12188116,  0.09840381, -0.01562682],\n",
       "       [ 0.02910218,  0.14305618,  0.07990658, -0.1565645 , -0.13092819,\n",
       "        -0.08532883,  0.18049982,  0.03910777, -0.06697257, -0.05407168],\n",
       "       [ 0.12531042, -0.01203017, -0.1744121 ,  0.10103938,  0.02096894,\n",
       "        -0.09169379,  0.02420288,  0.08498281, -0.09720147,  0.19150099],\n",
       "       [ 0.10903952,  0.00533283, -0.18580054,  0.12976024, -0.01562881,\n",
       "        -0.07137889,  0.15348023,  0.00997576,  0.22385591, -0.17635342],\n",
       "       [-0.14825137, -0.23353676, -0.11579394, -0.03495853, -0.22048049,\n",
       "         0.0445213 ,  0.02694643, -0.03694361, -0.02287818, -0.18122865],\n",
       "       [ 0.09832397,  0.12469524, -0.09253271, -0.02677949,  0.15094236,\n",
       "         0.1884923 , -0.2263805 ,  0.01850623, -0.1209257 , -0.08894151],\n",
       "       [ 0.08593148,  0.07196981,  0.1707209 , -0.06421082,  0.01522411,\n",
       "        -0.11959038, -0.04966497, -0.1419887 , -0.07590422, -0.11589406],\n",
       "       [ 0.03818911, -0.1008141 , -0.14925432, -0.20968308, -0.01553227,\n",
       "        -0.00413972, -0.07121702,  0.0188736 , -0.22561938, -0.19896473],\n",
       "       [-0.15567386,  0.04512805,  0.06774065,  0.14303559,  0.01233308,\n",
       "         0.04688808, -0.11729503, -0.16648981,  0.14894485,  0.09554458],\n",
       "       [-0.17317507, -0.2229515 , -0.05551921,  0.08935657, -0.2016641 ,\n",
       "        -0.07855554, -0.12259673,  0.22695786,  0.05206472, -0.2273713 ],\n",
       "       [-0.12167887, -0.06216693,  0.13237965,  0.14601627,  0.09801227,\n",
       "         0.01170014,  0.21087834,  0.11145052,  0.1398831 , -0.06081268],\n",
       "       [-0.20415908, -0.11366831, -0.03917827,  0.07830429, -0.22236238,\n",
       "         0.23318425, -0.0234123 ,  0.11383876, -0.09482494, -0.00799891],\n",
       "       [ 0.08114254, -0.06854036, -0.1499165 , -0.07781129,  0.03470328,\n",
       "        -0.03432992,  0.17566726, -0.1266418 ,  0.06229869, -0.20940326],\n",
       "       [-0.11080556,  0.11047262, -0.11028749, -0.013246  ,  0.2211214 ,\n",
       "         0.0902651 ,  0.09676045,  0.19038409, -0.09793235, -0.22683397],\n",
       "       [-0.00529903,  0.15628219, -0.2184057 , -0.14553368,  0.13315877,\n",
       "         0.03454319,  0.02113971,  0.08286843, -0.22358635, -0.05147371],\n",
       "       [-0.11509495, -0.03033514,  0.02139381,  0.11919975, -0.1184343 ,\n",
       "         0.13993016,  0.1376389 ,  0.06198353,  0.06456158, -0.0547538 ],\n",
       "       [ 0.23080727, -0.04536788,  0.01570238,  0.12626517, -0.05952613,\n",
       "         0.02332637,  0.10187462,  0.09432346, -0.10470809, -0.0974659 ],\n",
       "       [-0.08009127, -0.19975793, -0.02943109, -0.06057447, -0.1388079 ,\n",
       "        -0.0647976 , -0.18245201,  0.061396  , -0.08279711,  0.00028928],\n",
       "       [ 0.08031991, -0.20021169, -0.19667706, -0.09424533, -0.18138959,\n",
       "        -0.00452739, -0.09700875, -0.20999289,  0.0731599 ,  0.14553502],\n",
       "       [-0.05344954,  0.12495327,  0.1371795 ,  0.2018899 , -0.0356838 ,\n",
       "         0.20465377, -0.14264208, -0.04532813, -0.08226216, -0.01169463],\n",
       "       [-0.03821613, -0.08203219,  0.05713522, -0.17169903, -0.20996232,\n",
       "         0.13210842, -0.02662157, -0.19253723,  0.0629119 , -0.12716684],\n",
       "       [ 0.0481126 , -0.0964776 , -0.09776753,  0.11661708,  0.08148026,\n",
       "         0.07951424, -0.09619461, -0.02993473,  0.2161834 , -0.04313669],\n",
       "       [-0.03130464,  0.20750916, -0.19587424,  0.055161  ,  0.18017977,\n",
       "         0.14586508,  0.21011543,  0.02278247, -0.10188593, -0.09889327],\n",
       "       [ 0.09507772,  0.0778442 ,  0.06177035,  0.10487497, -0.06962863,\n",
       "         0.15196624, -0.1141214 ,  0.10569906,  0.2098611 , -0.04228663],\n",
       "       [-0.17157932,  0.12984839,  0.04812485,  0.13560712, -0.05064587,\n",
       "        -0.1948661 , -0.04382709,  0.21854958,  0.19297686, -0.08140582],\n",
       "       [ 0.15552247, -0.16241   , -0.08987798,  0.10077789, -0.00219288,\n",
       "         0.02993289, -0.22481392,  0.18089396, -0.16983962, -0.11975402],\n",
       "       [ 0.13126957, -0.22396877,  0.19513845,  0.08048227,  0.18204269,\n",
       "        -0.0501048 ,  0.0280917 ,  0.20407516, -0.22724023,  0.20560867],\n",
       "       [ 0.15202937, -0.03782991, -0.22316611,  0.20779237,  0.00909157,\n",
       "         0.12573212, -0.09801443, -0.1105365 ,  0.02010381,  0.09121159],\n",
       "       [-0.03855446,  0.10812038,  0.12169212, -0.10331987, -0.16762607,\n",
       "        -0.19838363,  0.2298905 ,  0.06523103,  0.12876469, -0.07010137],\n",
       "       [ 0.1479204 , -0.14750901,  0.10168508,  0.08265778,  0.01933384,\n",
       "         0.00507469,  0.0393554 ,  0.13113588, -0.12347268, -0.06653027],\n",
       "       [-0.22548868,  0.15721586,  0.1153473 ,  0.21927005, -0.17117661,\n",
       "         0.08259597, -0.14884344,  0.08475748,  0.03426528, -0.20969594],\n",
       "       [-0.01438232, -0.00513014,  0.11062354,  0.00342993, -0.07423507,\n",
       "         0.21218076, -0.14795485,  0.10385019,  0.0513424 , -0.0353566 ],\n",
       "       [-0.14442998,  0.18762815, -0.20455965,  0.0427458 , -0.00968298,\n",
       "        -0.21937351,  0.14352831, -0.07560593,  0.10463893, -0.06499822],\n",
       "       [-0.17329684,  0.11319011, -0.12016201,  0.02657869,  0.05438745,\n",
       "         0.02149186, -0.20772226,  0.17362776,  0.1300945 , -0.0565587 ],\n",
       "       [ 0.01292704, -0.10444778,  0.03598258,  0.18472615,  0.02701235,\n",
       "        -0.05981006,  0.18957981, -0.22947216,  0.22796032,  0.18696803],\n",
       "       [ 0.07811421,  0.04083711,  0.14415854, -0.07005382, -0.12810251,\n",
       "         0.15620041, -0.07650693,  0.21455508,  0.21663082,  0.11474416],\n",
       "       [-0.02691473,  0.08338934, -0.20292392, -0.08672768,  0.23137894,\n",
       "        -0.1482257 ,  0.20304525,  0.00463574,  0.12304938,  0.02554956],\n",
       "       [ 0.17423391,  0.06818727,  0.13019681, -0.09518854,  0.19364008,\n",
       "        -0.06896544, -0.11429608, -0.22918473,  0.22064877, -0.13308327],\n",
       "       [ 0.147143  ,  0.13700399,  0.05422956,  0.05449542,  0.06717825,\n",
       "         0.02782151, -0.1716899 ,  0.08617231, -0.10982671, -0.16307212],\n",
       "       [ 0.05522102,  0.06272408, -0.22999735, -0.10282046,  0.03233716,\n",
       "        -0.07019758, -0.1236287 , -0.15533954,  0.02454048, -0.15132916],\n",
       "       [-0.1565082 ,  0.03351697, -0.06345454,  0.00052381,  0.1935198 ,\n",
       "        -0.13937339, -0.16965024,  0.06278491,  0.02088198,  0.18275067],\n",
       "       [-0.14328493,  0.20518246, -0.23327178, -0.20559797, -0.12604438,\n",
       "         0.13365346,  0.16280311, -0.22768904,  0.08281282,  0.03506434],\n",
       "       [ 0.08841258, -0.14323893,  0.02820441, -0.20641416,  0.22865406,\n",
       "        -0.09543622,  0.10851249,  0.12668929,  0.16010654, -0.1709441 ],\n",
       "       [-0.17378162,  0.20867506,  0.2275598 ,  0.02292591,  0.22710878,\n",
       "         0.20535776,  0.17737615,  0.15328684, -0.04123636,  0.2140969 ],\n",
       "       [ 0.00645824,  0.07562396,  0.1710633 ,  0.08848163, -0.1213921 ,\n",
       "        -0.2198859 ,  0.05165729, -0.1710133 , -0.14666063,  0.14953196],\n",
       "       [-0.13201956, -0.1652982 , -0.03656225,  0.22037798,  0.19190857,\n",
       "         0.23324364,  0.20070738, -0.15580043,  0.17830032,  0.04864749],\n",
       "       [ 0.02228662,  0.15439472, -0.12022454,  0.01114643, -0.22893365,\n",
       "        -0.11019578,  0.07011595,  0.11678565, -0.11150526,  0.2277357 ],\n",
       "       [-0.1861005 ,  0.22666037,  0.15886524, -0.19825462, -0.13756059,\n",
       "        -0.04089424,  0.13042003,  0.16908178, -0.02718295,  0.0003601 ],\n",
       "       [ 0.05158591, -0.15635213, -0.06037791,  0.14342803, -0.02107669,\n",
       "         0.22250047, -0.07669073, -0.11638428, -0.21221545,  0.00658074],\n",
       "       [-0.08627494,  0.20914719,  0.09272331, -0.03289989,  0.0660474 ,\n",
       "        -0.20805898,  0.21273881,  0.1077472 , -0.04025628,  0.07701287],\n",
       "       [-0.05132614,  0.07797411, -0.1143894 , -0.06028837,  0.18667498,\n",
       "         0.1906878 , -0.03727414, -0.02523702,  0.15861952,  0.20987254],\n",
       "       [-0.0173116 , -0.05218048,  0.22690207,  0.0365862 ,  0.1721397 ,\n",
       "         0.07307386,  0.16861331,  0.04788172, -0.22477344, -0.10013081],\n",
       "       [ 0.11908355, -0.18794687, -0.2192141 , -0.15540558, -0.08540316,\n",
       "         0.04980451,  0.04738593,  0.08713835,  0.05613533, -0.2287366 ],\n",
       "       [-0.06263623,  0.11052877,  0.06556657,  0.21694201,  0.04678378,\n",
       "        -0.00795938, -0.08844154,  0.04766157, -0.1843093 , -0.04426365],\n",
       "       [-0.09326026, -0.07536092, -0.02533959, -0.18594424,  0.04458526,\n",
       "        -0.03803037, -0.10740028, -0.03683682, -0.06238782, -0.23113361],\n",
       "       [-0.00202957,  0.19162253,  0.00421166,  0.1832462 , -0.15141208,\n",
       "        -0.14890887, -0.22664984, -0.22848184,  0.06066579,  0.2255888 ],\n",
       "       [ 0.05409163,  0.18202102, -0.05394551, -0.10592581,  0.10885361,\n",
       "        -0.04286133,  0.13593516,  0.22860837,  0.1821011 ,  0.03696242],\n",
       "       [-0.05962613, -0.0510131 ,  0.1411975 ,  0.09685913,  0.15028885,\n",
       "         0.11127585,  0.16757584, -0.11774968, -0.1704871 , -0.04206212],\n",
       "       [-0.1740955 , -0.00198542, -0.14518782,  0.08263919, -0.01747642,\n",
       "         0.11349726, -0.2285922 ,  0.0270693 ,  0.03212383,  0.21972781],\n",
       "       [ 0.233154  ,  0.00985676, -0.15687867,  0.03640231, -0.05498376,\n",
       "         0.15673372,  0.16390097,  0.05826613, -0.18231508, -0.1259638 ],\n",
       "       [ 0.09119916,  0.1989733 , -0.14452264, -0.08808701,  0.01494248,\n",
       "        -0.16274309,  0.17559949,  0.00793454, -0.02480821,  0.09364736],\n",
       "       [ 0.07321927,  0.00475268,  0.15864307, -0.12342691, -0.2164617 ,\n",
       "        -0.19367298, -0.06014448, -0.18813865,  0.21187529, -0.16298065],\n",
       "       [-0.18810228,  0.08532664,  0.00900777,  0.1038664 , -0.08081965,\n",
       "        -0.19272594, -0.07075636, -0.03899279,  0.07259986,  0.12378883],\n",
       "       [-0.12339322,  0.09911868,  0.14053583,  0.0201498 , -0.19839343,\n",
       "        -0.06186308,  0.05975884,  0.22066128, -0.12984005, -0.00666308],\n",
       "       [ 0.02086654,  0.1946353 ,  0.07097781, -0.18786775,  0.05028138,\n",
       "        -0.1913816 , -0.19105335,  0.156028  ,  0.11290339,  0.21468347],\n",
       "       [-0.00347042,  0.0582276 ,  0.0488264 ,  0.0166747 , -0.03279053,\n",
       "        -0.10502186, -0.05115665,  0.02649298, -0.1391936 , -0.13365865],\n",
       "       [-0.0929402 , -0.02830853, -0.02947742,  0.02888149,  0.18819568,\n",
       "        -0.09177898, -0.22539602,  0.14377487, -0.19284678, -0.01035969],\n",
       "       [-0.20891126, -0.17932092,  0.12673897,  0.02099985, -0.15392303,\n",
       "        -0.14185935, -0.11003296, -0.01336092,  0.12045887,  0.23124442],\n",
       "       [ 0.17575678,  0.02244124, -0.10506319, -0.16574338, -0.22677472,\n",
       "        -0.15667519, -0.16613984, -0.21549995,  0.14570117,  0.19144392],\n",
       "       [ 0.1881035 ,  0.18242595, -0.05337499, -0.14139462, -0.06234562,\n",
       "        -0.16059837, -0.22370662,  0.13606915,  0.14819112,  0.00162999],\n",
       "       [-0.08515516,  0.12184781,  0.11196387,  0.17838663, -0.08992347,\n",
       "        -0.02654991, -0.16498399,  0.18549427, -0.19597758, -0.14932677],\n",
       "       [-0.19458257, -0.20829496, -0.1882147 ,  0.17617467,  0.20382887,\n",
       "         0.13043362, -0.19401772, -0.15644589, -0.02348112, -0.02859189],\n",
       "       [ 0.19032899,  0.1803996 ,  0.09257501,  0.17543933, -0.2271326 ,\n",
       "         0.08877012,  0.00984246, -0.21649963,  0.17458344,  0.11487791],\n",
       "       [-0.00491177, -0.13574585,  0.07810029, -0.16456693,  0.15639496,\n",
       "        -0.03870602,  0.16928035,  0.19254965,  0.00062804, -0.09785402],\n",
       "       [-0.06424028,  0.19620728,  0.06121877, -0.05485414,  0.05205631,\n",
       "         0.04691097,  0.2004641 , -0.06572655, -0.15176784, -0.10020125]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_5/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([784, 300])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([300, 100])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 10])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input.name\n",
    "#weights0, biases0 = input.weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2239 - accuracy: 0.9189 - val_loss: 0.3080 - val_accuracy: 0.8908\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2204 - accuracy: 0.9207 - val_loss: 0.2937 - val_accuracy: 0.8962\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2169 - accuracy: 0.9218 - val_loss: 0.3502 - val_accuracy: 0.8676\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2136 - accuracy: 0.9234 - val_loss: 0.2967 - val_accuracy: 0.8942\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2097 - accuracy: 0.9246 - val_loss: 0.3486 - val_accuracy: 0.8716\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2069 - accuracy: 0.9251 - val_loss: 0.2900 - val_accuracy: 0.8968\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2034 - accuracy: 0.9277 - val_loss: 0.2881 - val_accuracy: 0.8970\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2003 - accuracy: 0.9283 - val_loss: 0.2860 - val_accuracy: 0.8956\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1980 - accuracy: 0.9292 - val_loss: 0.2895 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1951 - accuracy: 0.9297 - val_loss: 0.2985 - val_accuracy: 0.8928\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1901 - accuracy: 0.9321 - val_loss: 0.2888 - val_accuracy: 0.9008\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1878 - accuracy: 0.9329 - val_loss: 0.2993 - val_accuracy: 0.8948\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1859 - accuracy: 0.9335 - val_loss: 0.3033 - val_accuracy: 0.8892\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1822 - accuracy: 0.9346 - val_loss: 0.2890 - val_accuracy: 0.9016\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1803 - accuracy: 0.9360 - val_loss: 0.2837 - val_accuracy: 0.8982\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1766 - accuracy: 0.9374 - val_loss: 0.2923 - val_accuracy: 0.8972\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1731 - accuracy: 0.9380 - val_loss: 0.3049 - val_accuracy: 0.8970\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1716 - accuracy: 0.9389 - val_loss: 0.3104 - val_accuracy: 0.8860\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1685 - accuracy: 0.9402 - val_loss: 0.2903 - val_accuracy: 0.8988\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1659 - accuracy: 0.9411 - val_loss: 0.3182 - val_accuracy: 0.8866\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1631 - accuracy: 0.9431 - val_loss: 0.2892 - val_accuracy: 0.9004\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9440 - val_loss: 0.3148 - val_accuracy: 0.8888\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1576 - accuracy: 0.9447 - val_loss: 0.3139 - val_accuracy: 0.8922\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1552 - accuracy: 0.9442 - val_loss: 0.2920 - val_accuracy: 0.9006\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1534 - accuracy: 0.9450 - val_loss: 0.2868 - val_accuracy: 0.9026\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1504 - accuracy: 0.9467 - val_loss: 0.2975 - val_accuracy: 0.9028\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1491 - accuracy: 0.9465 - val_loss: 0.2948 - val_accuracy: 0.8994\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1452 - accuracy: 0.9486 - val_loss: 0.2861 - val_accuracy: 0.9008\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1434 - accuracy: 0.9505 - val_loss: 0.3001 - val_accuracy: 0.8984\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9509 - val_loss: 0.2931 - val_accuracy: 0.8976\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1390 - accuracy: 0.9504 - val_loss: 0.3038 - val_accuracy: 0.8982\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1376 - accuracy: 0.9517 - val_loss: 0.3031 - val_accuracy: 0.9004\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1343 - accuracy: 0.9519 - val_loss: 0.2968 - val_accuracy: 0.8980\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1322 - accuracy: 0.9536 - val_loss: 0.3201 - val_accuracy: 0.8952\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1304 - accuracy: 0.9544 - val_loss: 0.3143 - val_accuracy: 0.8994\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1272 - accuracy: 0.9555 - val_loss: 0.3058 - val_accuracy: 0.8978\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1269 - accuracy: 0.9553 - val_loss: 0.3323 - val_accuracy: 0.8910\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1244 - accuracy: 0.9571 - val_loss: 0.3024 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1219 - accuracy: 0.9577 - val_loss: 0.2965 - val_accuracy: 0.9004\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1197 - accuracy: 0.9584 - val_loss: 0.2949 - val_accuracy: 0.9022\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1173 - accuracy: 0.9585 - val_loss: 0.3121 - val_accuracy: 0.8956\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1160 - accuracy: 0.9591 - val_loss: 0.3127 - val_accuracy: 0.9020\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1158 - accuracy: 0.9585 - val_loss: 0.3137 - val_accuracy: 0.8982\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1119 - accuracy: 0.9616 - val_loss: 0.3343 - val_accuracy: 0.8942\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1093 - accuracy: 0.9624 - val_loss: 0.3056 - val_accuracy: 0.9028\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1085 - accuracy: 0.9626 - val_loss: 0.3285 - val_accuracy: 0.8964\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9629 - val_loss: 0.3068 - val_accuracy: 0.9008\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9636 - val_loss: 0.3174 - val_accuracy: 0.9018\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 0.3179 - val_accuracy: 0.8954\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1022 - accuracy: 0.9649 - val_loss: 0.3236 - val_accuracy: 0.8978\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0998 - accuracy: 0.9647 - val_loss: 0.3497 - val_accuracy: 0.8936\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0983 - accuracy: 0.9664 - val_loss: 0.3280 - val_accuracy: 0.8958\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0965 - accuracy: 0.9666 - val_loss: 0.3603 - val_accuracy: 0.8952\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0956 - accuracy: 0.9671 - val_loss: 0.3157 - val_accuracy: 0.9008\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9682 - val_loss: 0.3425 - val_accuracy: 0.8946\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9686 - val_loss: 0.3214 - val_accuracy: 0.8998\n",
      "Epoch 57/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0897 - accuracy: 0.9693 - val_loss: 0.3285 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0892 - accuracy: 0.9690 - val_loss: 0.3421 - val_accuracy: 0.9004\n",
      "Epoch 59/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0862 - accuracy: 0.9707 - val_loss: 0.3354 - val_accuracy: 0.8976\n",
      "Epoch 60/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.3363 - val_accuracy: 0.8990\n",
      "Epoch 61/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.4485 - val_accuracy: 0.8842\n",
      "Epoch 62/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9727 - val_loss: 0.3541 - val_accuracy: 0.8970\n",
      "Epoch 63/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0812 - accuracy: 0.9720 - val_loss: 0.3507 - val_accuracy: 0.8954\n",
      "Epoch 64/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0805 - accuracy: 0.9729 - val_loss: 0.3465 - val_accuracy: 0.8972\n",
      "Epoch 65/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9729 - val_loss: 0.3398 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9733 - val_loss: 0.3523 - val_accuracy: 0.8996\n",
      "Epoch 67/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 0.3449 - val_accuracy: 0.9012\n",
      "Epoch 68/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.3708 - val_accuracy: 0.8928\n",
      "Epoch 69/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0735 - accuracy: 0.9754 - val_loss: 0.3548 - val_accuracy: 0.9006\n",
      "Epoch 70/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0716 - accuracy: 0.9754 - val_loss: 0.3430 - val_accuracy: 0.9040\n",
      "Epoch 71/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0711 - accuracy: 0.9768 - val_loss: 0.3616 - val_accuracy: 0.8990\n",
      "Epoch 72/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0691 - accuracy: 0.9765 - val_loss: 0.3553 - val_accuracy: 0.9006\n",
      "Epoch 73/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0688 - accuracy: 0.9767 - val_loss: 0.3949 - val_accuracy: 0.8864\n",
      "Epoch 74/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9768 - val_loss: 0.3720 - val_accuracy: 0.9022\n",
      "Epoch 75/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.3556 - val_accuracy: 0.9038\n",
      "Epoch 76/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0650 - accuracy: 0.9777 - val_loss: 0.3581 - val_accuracy: 0.9008\n",
      "Epoch 77/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0642 - accuracy: 0.9784 - val_loss: 0.3762 - val_accuracy: 0.9010\n",
      "Epoch 78/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.3927 - val_accuracy: 0.8944\n",
      "Epoch 79/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0613 - accuracy: 0.9794 - val_loss: 0.3657 - val_accuracy: 0.8990\n",
      "Epoch 80/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0596 - accuracy: 0.9802 - val_loss: 0.3767 - val_accuracy: 0.9016\n",
      "Epoch 81/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.3919 - val_accuracy: 0.8950\n",
      "Epoch 82/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0582 - accuracy: 0.9808 - val_loss: 0.3730 - val_accuracy: 0.9002\n",
      "Epoch 83/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 0.3745 - val_accuracy: 0.9004\n",
      "Epoch 84/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.3851 - val_accuracy: 0.9002\n",
      "Epoch 85/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0540 - accuracy: 0.9828 - val_loss: 0.3739 - val_accuracy: 0.9022\n",
      "Epoch 86/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0523 - accuracy: 0.9831 - val_loss: 0.3930 - val_accuracy: 0.8952\n",
      "Epoch 87/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0537 - accuracy: 0.9826 - val_loss: 0.4006 - val_accuracy: 0.8988\n",
      "Epoch 88/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 0.3860 - val_accuracy: 0.9020\n",
      "Epoch 89/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.3876 - val_accuracy: 0.9004\n",
      "Epoch 90/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.3898 - val_accuracy: 0.9002\n",
      "Epoch 91/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.3973 - val_accuracy: 0.8982\n",
      "Epoch 92/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.4029 - val_accuracy: 0.8998\n",
      "Epoch 93/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.4237 - val_accuracy: 0.8984\n",
      "Epoch 94/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.4036 - val_accuracy: 0.8986\n",
      "Epoch 95/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.3830 - val_accuracy: 0.9022\n",
      "Epoch 96/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 0.4065 - val_accuracy: 0.9018\n",
      "Epoch 97/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.4060 - val_accuracy: 0.9030\n",
      "Epoch 98/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.4000 - val_accuracy: 0.9002\n",
      "Epoch 99/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0429 - accuracy: 0.9863 - val_loss: 0.4169 - val_accuracy: 0.9024\n",
      "Epoch 100/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0412 - accuracy: 0.9872 - val_loss: 0.4343 - val_accuracy: 0.8964\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj70lEQVR4nO3deZhc1X3m8e+v9q7eN7WkllpqQKwCIRD7GOMQHmPGNhAPsYkdG5nl8SR4MuPEfnDsOI7teewkkzhxwsTRJGATDwYCOCExgRiDBztmk7AwICEktKBubb0v1V1d25k/TvUm1FIJVavpq/fzPPWo6t5z7z23L7x96txzT5tzDhERmf9Cc10BEREpDwW6iEhAKNBFRAJCgS4iEhAKdBGRgIjM1YGbmprc8uXL5+rwIiLz0oYNG7qdc82HWjdngb58+XLWr18/V4cXEZmXzGzXTOvU5SIiEhAKdBGRgDhioJvZXWZ2wMxemWG9mdm3zGybmf3SzM4rfzVFRORISmmhfwe4+jDr3wesKL5uA/7m2KslIiJH64iB7px7Gug9TJFrgXuc9yxQZ2aLylVBEREpTTn60FuB3VM+dxSXiYjIcXRcb4qa2W1mtt7M1nd1dR3PQ4uIBF45xqF3AkunfF5SXPYWzrl1wDqANWvWaN5eEXnnKRQgMwxjg5Abg3AMInFwzi9LD0J2BCwEoTBYGMJRXw5geB8M7oFUF0QSEK+GaNJvkx7w25/6Xmgt//iRcgT6I8DtZnYfcBEw4JzbW4b9ikgQjP/NBbPpywsFGBuAkV4Y7YNMygdnJOH/tbAPTCgGYT+M9sNIT3GbXsiOQj4L+YzfJlrht8+lfXCODYErQCgCoRBkRvx2o32Qy0zWq5Dz+8hlfPAyy+3NqgVzE+hm9n3gCqDJzDqAPwSiAM65bwOPAtcA24ARYG3Zayki5ZPPQSE75XPWtyaHD/iwDIUhFIVwxIdhIe9fLj/5eWzQh+Jon/8cCvvQzI35EB0b8vsc7PSt1VwaYlUQqwTMr88MHdt5xGshmoBw3Nd1PIyzoz7YEzW+dWzh4jnkIJaEZBM0rvC/AHA+u0Nh/zkc863pRA3Ea/yyfMa/nINE7WSLG1f8uRQmf6m4AlS1QM1iqGz2y8aGfL2iycntx39RldkRA905d+MR1jvgt8tWI5ETRXZ0Mgwt5Fuo41/pU12TIWvmwzBe7UMpPehbtvkpoVzI+TDNZ/x+x4aK3QZDvlWbHvDvc2kfzOUSivogL+T8KxL39YxVQWUTtKyEU6/2reZMytfJucnATNRARQMkG3zg5TP+PHLp4i+PnD9OvAYq6iBRB8lGXz4cLd95zKZkw3E71JzN5SIyLxQKMNJdbInmfIgWcj5wcmkfUiO9vmWb7i+GUfGVGfbrs6M+9MJRH85D+2Gww4dsudiUFmYk4YNy/JfAgtOLLcOayS6NUGSyC8TCvjVZtcCHJa7Y4sxO9hGHQpNdIBby+61o8C3ug7tSZM4o0GV+K+Shb6dvhY4N+hDNZ6d0FWQnQzg7UmwlpiaXFbLF7oFuH8z5zGT3wdggDO6d3j1xOON9v5FiN0C82MUQrSjeaEv51nH9Mlh2KdQsKrZui90Z0crJlmtlk//qXtkEWLG1PezrNt6yjcRn8Qcr85ECXY6/bNr3raa6IZuaDNnxV25sSn9tzt/Iyo74EI4m/FfzQh72vuRf2dTRHT+a9C3ZUGQyIJONPmgj8cl+0WgF1LT6V7JhspUdik723caSftuKBr9stiRqZm/fEhgKdCldoeC7FfKZydbv8AEY2O1vfI32+dZuetCXGx+9MLXVO9oPqQOlH9PCk63ccKzYzTHiA3fhSlj9MVi0yrdkx/tuw9HJ7oFpIVzhwzykOekkmBToJwLnfKhasR80m4Le7dDzBvTtgL5d0P8mDO31gTneHRGO+xZrKOKHeqW6D39DzUK+tTt+A6ui3t/tD8f8doW8D926NqhdApULfFgf/IokJvttRaRkCvR3ukLet377dvqbc+mByRELY8O+bxUHkQrfAnWFmYeNzaSy2Yds0wq/n3DMh2k+OxnwyQt8uWRTMeSLrd/KBVDb6oM7UacbZCJzSIF+vOQyfiREJlUcKztS7J4oBnSqe3KoWrrfLxvt82Gcz7x1fxaaPq43N+pHU0y0kqt9C3nRKjjtGv/eOd9SDseg4SRoPAUa2ov7EJH5ToF+tPLFURFjg76FnB31YTo2NPn0Wqrb9y0P7/evoX1++ZEk6oqt4Ab/b+Mp/oZcQzvULfOjHhK1/qXhYiJykBM70LNp3xIeH2kxfkNvfPhbdtS3pAc6oft16Nriuz2OJByH6hYfwPXt0HYxVC2Eqmbfqo4Wu0fitZNPsyWbIBKb/XMWkcAKXqA757sqhvb67ovxeR+yo5MPgvRsgwOboHcHJc3ZkKiD5tPg9GugdunkOOBYpR87HE349+PD19R6FpE5MP8CffiAD+P+N/1roNOH9nhXx/hIjZlY2Pcft6yEs399Sqs56VvKiRrfch4fKjc+XE4BLSLvcPMv0H/xPfjxH/n3FoLqRZNzO9S1+c81rf4pvMrm6a3mSMJP4iMiEkDzL93Ouh6WXODDu2bx/JmgR0Rkls2/QG9o9y8REZlGj+KJiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBUVKgm9nVZrbFzLaZ2R2HWN9mZk+Z2S/M7Jdmdk35qyoiIodzxEA3szBwJ/A+4EzgRjM786BiXwQecM6tBj4C/O9yV1RERA6vlBb6hcA259x251wGuA+49qAyDqgpvq8F9pSviiIiUopSAr0V2D3lc0dx2VRfBj5mZh3Ao8CnD7UjM7vNzNab2fqurq63UV0REZlJuW6K3gh8xzm3BLgG+Acze8u+nXPrnHNrnHNrmpuby3RoERGB0gK9E1g65fOS4rKpbgYeAHDOPQMkgKZyVFBEREpTSqC/AKwws3Yzi+Fvej5yUJk3gSsBzOwMfKCrT0VE5Dg6YqA753LA7cDjwGb8aJZXzewrZvbBYrHfBW41s5eA7wM3OefcbFVaRETeKlJKIefco/ibnVOXfWnK+03AZeWtmoiIHA09KSoiEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQJQW6mV1tZlvMbJuZ3TFDmV83s01m9qqZ3VveaoqIyJFEjlTAzMLAncBVQAfwgpk94pzbNKXMCuDzwGXOuT4zWzBbFRYRkUMrpYV+IbDNObfdOZcB7gOuPajMrcCdzrk+AOfcgfJWU0REjqSUQG8Fdk/53FFcNtWpwKlm9h9m9qyZXX2oHZnZbWa23szWd3V1vb0ai4jIIZXrpmgEWAFcAdwI/B8zqzu4kHNunXNujXNuTXNzc5kOLSIiUEIfOtAJLJ3yeUlx2VQdwHPOuSyww8xexwf8C2WppYjMO9lslo6ODtLp9FxXZV5KJBIsWbKEaDRa8jalBPoLwAoza8cH+UeA3ziozD/hW+Z3m1kTvgtme8m1EJHA6ejooLq6muXLl2Nmc12decU5R09PDx0dHbS3t5e83RG7XJxzOeB24HFgM/CAc+5VM/uKmX2wWOxxoMfMNgFPAZ91zvUc9VmISGCk02kaGxsV5m+DmdHY2HjU325KaaHjnHsUePSgZV+a8t4Bnym+REQAFObH4O387PSkqIgEVlVV1VxX4bhSoIuIBIQCXUQCzznHZz/7WVauXMnZZ5/N/fffD8DevXu5/PLLOffcc1m5ciU//elPyefz3HTTTRNlv/nNb85x7UtXUh+6iMix+KN/eZVNewbLus8zF9fwhx84q6SyDz/8MBs3buSll16iu7ubCy64gMsvv5x7772X9773vXzhC18gn88zMjLCxo0b6ezs5JVXXgGgv7+/rPWeTWqhi0jg/exnP+PGG28kHA7T0tLCu9/9bl544QUuuOAC7r77br785S/z8ssvU11dzUknncT27dv59Kc/zWOPPUZNTc1cV79kaqGLyKwrtSV9vF1++eU8/fTT/PCHP+Smm27iM5/5DB//+Md56aWXePzxx/n2t7/NAw88wF133TXXVS2JWugiEnjvete7uP/++8nn83R1dfH0009z4YUXsmvXLlpaWrj11lu55ZZbePHFF+nu7qZQKPChD32Ir33ta7z44otzXf2SqYUuIoF3/fXX88wzz7Bq1SrMjD/5kz9h4cKFfPe73+VP//RPiUajVFVVcc8999DZ2cnatWspFAoAfP3rX5/j2pfO/DNBx9+aNWvc+vXr5+TYIjL7Nm/ezBlnnDHX1ZjXDvUzNLMNzrk1hyqvLhcRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiJyDHK53FxXYYICXUQC67rrruP888/nrLPOYt26dQA89thjnHfeeaxatYorr7wSgOHhYdauXcvZZ5/NOeecw0MPPQRM/wMZDz74IDfddBMAN910E5/61Ke46KKL+NznPsfzzz/PJZdcwurVq7n00kvZsmULAPl8nt/7vd9j5cqVnHPOOfzVX/0VTz75JNddd93Efn/0ox9x/fXXl+V89ei/iMy+f7sD9r1c3n0uPBve943DFrnrrrtoaGhgdHSUCy64gGuvvZZbb72Vp59+mvb2dnp7ewH46le/Sm1tLS+/7OvY19d3xMN3dHTw85//nHA4zODgID/96U+JRCI88cQT/P7v/z4PPfQQ69atY+fOnWzcuJFIJEJvby/19fX81m/9Fl1dXTQ3N3P33XfzyU9+8th/HijQRSTAvvWtb/GDH/wAgN27d7Nu3Touv/xy2tvbAWhoaADgiSee4L777pvYrr6+/oj7vuGGGwiHwwAMDAzwiU98gq1bt2JmZLPZif1+6lOfIhKJTDveb/7mb/K9732PtWvX8swzz3DPPfeU5XwV6CIy+47Qkp4NP/nJT3jiiSd45plnSCaTXHHFFZx77rm89tprJe9j6h9qTqfT09ZVVlZOvP+DP/gD3vOe9/CDH/yAnTt3csUVVxx2v2vXruUDH/gAiUSCG264YSLwj5X60EUkkAYGBqivryeZTPLaa6/x7LPPkk6nefrpp9mxYwfARJfLVVddxZ133jmx7XiXS0tLC5s3b6ZQKEy09Gc6VmtrKwDf+c53JpZfddVV/O3f/u3EjdPx4y1evJjFixfzta99jbVr15btnBXoIhJIV199NblcjjPOOIM77riDiy++mObmZtatW8ev/dqvsWrVKj784Q8D8MUvfpG+vj5WrlzJqlWreOqppwD4xje+wfvf/34uvfRSFi1aNOOxPve5z/H5z3+e1atXTxv1csstt9DW1sY555zDqlWruPfeeyfWffSjH2Xp0qVlnZFS0+eKyKzQ9LmHd/vtt7N69WpuvvnmGcsc7fS56kMXETnOzj//fCorK/mzP/uzsu5XgS4icpxt2LBhVvarPnQRkYBQoIvIrJmre3RB8HZ+dgp0EZkViUSCnp4ehfrb4Jyjp6eHRCJxVNupD11EZsWSJUvo6Oigq6trrqsyLyUSCZYsWXJU2yjQRWRWRKPRiUfs5fhQl4uISEAo0EVEAqKkQDezq81si5ltM7M7DlPuQ2bmzOyQTzGJiMjsOWKgm1kYuBN4H3AmcKOZnXmIctXA7wDPlbuSIiJyZKW00C8EtjnntjvnMsB9wLWHKPdV4I+B9CHWiYjILCsl0FuB3VM+dxSXTTCz84ClzrkfHm5HZnabma03s/UayiQiUl7HfFPUzELAnwO/e6Syzrl1zrk1zrk1zc3Nx3poERGZopRA7wSWTvm8pLhsXDWwEviJme0ELgYe0Y1REZHjq5RAfwFYYWbtZhYDPgI8Mr7SOTfgnGtyzi13zi0HngU+6JzTZOciIsfREQPdOZcDbgceBzYDDzjnXjWzr5jZB2e7giIiUpqSHv13zj0KPHrQsi/NUPaKY6+WiIgcLT0pKiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiATHvAn0kkyOTK8x1NURE3nEic12Bo/XAC7v5+r+9xuq2Oi5sb+TC5Q2sbqujMj7vTkVEpKzmXQquWlrHRy9axvM7e/jrJ7dScBAOGSsX17BmeQPnL6vnvLZ6FtYm5rqqIiLHlTnn5uTAa9ascevXrz+mfQyms2zY1cf6nb28sLOPjbv7J7pjWusquOTkRi47pZHLTm5iQY0CXkTmPzPb4Jxbc8h1pQS6mV0N/CUQBv7OOfeNg9Z/BrgFyAFdwCedc7sOt89yBPrBMrkCm/YOToT8M9t76B/JArCoNsFZi2s4c1ENq5fVc/6yemoS0bIeX0Rkth1ToJtZGHgduAroAF4AbnTObZpS5j3Ac865ETP7r8AVzrkPH26/sxHoBysUHJv2DvLMGz28smeATXsGeaNrmIKDkMEZi2o4f1k9q5bUcW5bHe2NlYRCNqt1EhE5FocL9FL60C8Etjnnthd3dh9wLTAR6M65p6aUfxb42NuvbvmEQsbK1lpWttZOLBvJ5PjFm/08v6OX53f08tCGDu55xn+ZiEdCtDdVcnJzFactrObs4rbN1fG5OgURkZKVEuitwO4pnzuAiw5T/mbg3w61wsxuA24DaGtrK7GK5ZWMRbjslCYuO6UJgHzBse3AMC/t7mfrgSG2d6V4Zc8Aj76yl/EvLyc1V/L+sxdxzTmLOK2lGjO14kXknaeso1zM7GPAGuDdh1rvnFsHrAPf5VLOY79d4ZBx2sJqTltYPW358FiOVzsHeLlzgCdfO8BfP7WNbz25jZaaOKcsqOLk5ipOaqqkrTFJW0OSpQ1J4pHwHJ2FiEhpgd4JLJ3yeUlx2TRm9qvAF4B3O+fGylO9uVMVj3DRSY1cdFIjt7zrJLqGxnj81X28+GYfb3SlePjFTobHchPlY+EQ57bVcclJjZy/rJ5ljUkW1VYQi8y7Z7dEZJ4q5aZoBH9T9Ep8kL8A/IZz7tUpZVYDDwJXO+e2lnLg43FTdDY55+gezvBm7wi7e0d4dc8Az+3o5ZXOAQrFH6mZHz55YXsDl57cxCUnN9JaVzG3FReRea0cwxavAf4CP2zxLufc/zSzrwDrnXOPmNkTwNnA3uImbzrnPni4fc73QJ/JwGiWTXsG6ewfpaNvhNf3D/Hs9l56UxnAB/ya5f7hpyX1FSyoTtBSG6e5Kq6+eRE5omMO9NkQ1EA/lELBsWX/EM9u72H9zj6e39lL19D0XqmmqjjnLq3lnCV1nLW4hjMW1bCoNqGQF5FpjnXYohyjUMg4Y5EP6bWXteOcY//gGPsG0+wfTLOnf5SXOwd4aXc/T2w+MLFdbUWUMxZVc9biWs5aXMNZi2s5ubmSSFj98iLyVgr0OWBmLKxNHHK+maF0li37hti8d5BNe4fYtHeQ7z27i7HilAbxSIjTF/knXk9fWM3pxRE6dcnY8T4NEXmHUZfLPJDLF9jRneLVPYO80jnAq3sG2bxvcGJaA4CmqpgfStlcyZL6JEvqK2hvquS0hdUaTikSIOpymeci4RArWqpZ0VLNdatbASa6bTbvG2Tr/iG2HRhm24FhfrRpP93DmYlto2Hj1JZqTmupprnG33xd2pDkovYGtepFAkaBPk9N7bZ5z2kLpq0bzeTp6Bth64FhXu4c4OWOAZ7d3kP3cIZMvlDcHlYuruXC9gbaGnyLflljkpOaqjSfjcg8pUAPoIpYeKJFf83ZiyaWO+cYHM2xrWuI/9jWw8+2dU/rnweoSUS4YHkD5y2rp6kqRk0iSk1FlMaqGE1VceqTMcIKfJF3JPWhn+DGH5Dq6Bvhja4U63f28vzOXrZ3pQ5ZPlIcsXP+snpWt9Vx2sJqljVUUhFTP73I8aBx6HLUhsdyDIxmGRzN0j+SpSc1Rs9whr0DaV7a3c/G3f2MZvMT5RfWJGhrSNJaX0FrXQWnLqxm9dI6ltRXaCy9SBnppqgctap4hKp4ZMapCnL5Alv2+9kpd3an2NGToqNvlOd39LJvME2+OP9BY2WMxXUVRMNGLBKiuTrBqQuqWNFSzaktVSxrrFQXjkiZKNDlbYmEQ8UHnmrfsi6bL7Bl3xAbd/fz0u5+elIZMrkCY7k8v3izj395ac9E2XgkxMnNVaxoqaK9qZKTirNYntxcpW4ckaOkLhc57lJjObYdGOb1/UNsPTDMln1+2OWegdGJOejNYGl9kvamSpqq4jRVxahNRomEjJAZyViEC5bXc8qCKnXpyAlFXS7yjlIZj7BqaR2rltZNW57O5tnZk+KNAym2HvBhv6snxdb9Q3QXW/kHW1iT4NJTGlm5uJbTF/qRPQ2VGokjJyYFurxjJKJhTl9Yw+kLa4BF09Y55xjLFcgVHPmCo38kw8/f6OFnW7v5f1u6ePjF6VP0V0TDVCUiNFbGaK6O01zt/zDJ+Lw49ckYhv8moBa+BIUCXeYFMyMRnexTr62IsqyxkhsvbMM5R9fw2ETXzcBoltRYjqF0jp5Uhq6hMbYdGH5L6I+rT0Zpa6xkeaPv4jllQRWnLKhieWPltGOKvNMp0GXeMzMWVCdYUJ3gXSuaZyw3Plf9pr2DpMZyOAeF4i+DXT0p1u/s45GX9jD1tlJtRZSFNf6J3MV1FbTWJVhQk6C2IkpNIkpzdYxljZVENQOmvAMo0OWEUVsR5ZKTG7nk5MYZy6SzebZ3pdjWNczu3hH2D6bZN5Bm70CaVzoH6Ell3rJNNGyc3FzFyQuqaKlO0FwdZ0G1nzOnrSHJguq4plOQ40KBLjJFIhrmzMU1nLm45pDr09k8XUNj/qGrdJb9g2m27PMjdl7tHOAnQwdIZfLTtomEjIpYmEQ0TFU8wooFVZzdWstZrTVUxaOEQxAyo60hSWNV/HicpgSUAl3kKCSiYZY2JKf91fSDpcZy7B9Ms7tvlDd7R9jbP8pIJs9YLs/gaI7Newf59037D7ltc3Wc0xdW01pXQX1ljMbKGPXJGHXJKHXJGDWJCMl4hMpYmJpEVC1/mUaBLlJmlfGIf0CquWrGMoPpLK/vGyKdLVBwjmxxzvvNe4fYsn+Q1/YN0ZfKkCvM/JxILBKirSHJ8sYkC2t9v35thQ/+5mo/VXJLTYKmqphG8pwgFOgic6AmEWXN8obDlnHOMZjO0T+SoW8kS99IhtRYjpGxPMNjOfYPpdnZnWJn9wgbdvUxmM5NTLkwVSwSorWugpaaONWJKNXxCDUVUZbUV9DWkGRxXQXJWJh4NEwyGqYuGdUvgHlKgS7yDmVmE63uZTPfx53gnCOVydM7nKFreIyuIX9Dd89Ams6+Ud8N1DvC8FiOvlTmLX3945KxMG0NSZY2JEnGwkRCIWIRozIWoToRpaYiQmOVv/G7oNp/C6iMK0reCXQVRALCzCYmVWtrTB62rHOO/pGs7+MfSJPO+j7+4TH/x1F29YywqydFOlsgX3Bk8gX/7WCGXwJV8QgtNX6+/OpEhKpElJbiw1wrWqpoqUkQj4SJR0NUxiJ6kneWKNBFTkBmRn1ljPrKGKsOd4f3INl8gaF0ju7hMQ4MjnFgKM2BoTH2DaTZP5hmYDRLTyrDzp4R/r1/dNofTxkXDhkLaxK01lXQWl/hbzLXV9BUHWcs6ydxyxccyViYqniU6kSEpmo/n4/+Pu7hKdBFpGTRcIiGyhgNlTFObak+bNl8wdHZN8rWA0N0D48VZ9ws0DeSYU9/ms5+P93yP2/s5DD3fqepT0Zpa0jS1ljJsmL//6JaP/Y/NZaja3iM3lSGeCREbYUfHbSgOs7iuooT4qlfBbqIzIpwyGhrTB6x+yeTK7B3YJSeYhAnomHCZqQyOVJjeQZHs8V7AmPsK94H2Li7j0df3nvIm8AzqU9GWd5UySnF6ZrjkTD9I1n6RzPEwqHik8D+G8OyxuS8/AWgQBeRORWLhFjWWMmyxsqj2i6XL9A1PMbegTQHBseoikdoqvbfHjK5Av0jWQZG/cNfe/pH6exPs6N7mKe2dPGPGzom9lMVj5DJF6bN5mkGrXUVLKiOk3dQKDjM/Pz98UiYRDRERSxCMurfxyIhouEQyViY0xbWcHZrLS01cZyD3pEMfanMxHMFszmCSIEuIvNSJBxiUW0Fi2oP/Ve1ltTPvG3/iB/jX1sRJRoOUSg4elIZOvtH2dWTYkd3iu1dKXpTGUIhI2zg8N8mRrN5elMZ0tk8I5k8o9k82Xyh+Jr8xlCdiDCSyU/7FhGLhFhUm+AzV53Ktee2lutHMUGBLiInnLpkbNrnUMgmplk+96B5+o/GSMY/CfxyxwBvdKWoqYiwoDpBXTJKX8r/Td49A2kaK2dnigcFuohImSRjEc5f1sD5yw7/0Nhs0ZyfIiIBoUAXEQkIBbqISECUFOhmdrWZbTGzbWZ2xyHWx83s/uL658xsedlrKiIih3XEQDezMHAn8D7gTOBGMzvzoGI3A33OuVOAbwJ/XO6KiojI4ZXSQr8Q2Oac2+6cywD3AdceVOZa4LvF9w8CV5rm3xQROa5KCfRWYPeUzx3FZYcs45zLAQNACRN+iohIuRzXm6JmdpuZrTez9V1dXcfz0CIigVfKg0WdMO1PKC4pLjtUmQ4ziwC1QM/BO3LOrQPWAZhZl5ntejuVBpqA7re57Xx2Ip73iXjOcGKe94l4znD0571sphWlBPoLwAoza8cH90eA3ziozCPAJ4BngP8CPOmcO+w0aM655hKOfUhmtt45t+btbj9fnYjnfSKeM5yY530injOU97yPGOjOuZyZ3Q48DoSBu5xzr5rZV4D1zrlHgL8H/sHMtgG9+NAXEZHjqKS5XJxzjwKPHrTsS1Pep4Ebyls1ERE5GvP1SdF1c12BOXIinveJeM5wYp73iXjOUMbztiN0dYuIyDwxX1voIiJyEAW6iEhAzLtAP9JEYUFgZkvN7Ckz22Rmr5rZ7xSXN5jZj8xsa/Hfw/yRrfnJzMJm9gsz+9fi5/bihG/bihPAxY60j/nGzOrM7EEze83MNpvZJSfItf4fxf++XzGz75tZImjX28zuMrMDZvbKlGWHvLbmfat47r80s/OO9njzKtBLnCgsCHLA7zrnzgQuBn67eJ53AD92zq0Aflz8HDS/A2ye8vmPgW8WJ37rw08EFzR/CTzmnDsdWIU//0BfazNrBf4bsMY5txI/JPojBO96fwe4+qBlM13b9wEriq/bgL852oPNq0CntInC5j3n3F7n3IvF90P4/8FbmT4J2neB6+akgrPEzJYA/xn4u+JnA34FP+EbBPOca4HL8c9y4JzLOOf6Cfi1LooAFcWny5PAXgJ2vZ1zT+OfzZlqpmt7LXCP854F6sxs0dEcb74FeikThQVKcW751cBzQItzbm9x1T6gZa7qNUv+AvgcUCh+bgT6ixO+QTCvdzvQBdxd7Gr6OzOrJODX2jnXCfwv4E18kA8AGwj+9YaZr+0x59t8C/QTiplVAQ8B/905Nzh1XXFqhcCMOTWz9wMHnHMb5roux1kEOA/4G+fcaiDFQd0rQbvWAMV+42vxv9AWA5W8tWsi8Mp9bedboJcyUVggmFkUH+b/1zn3cHHx/vGvYMV/D8xV/WbBZcAHzWwnvivtV/B9y3XFr+QQzOvdAXQ4554rfn4QH/BBvtYAvwrscM51OeeywMP4/waCfr1h5mt7zPk23wJ9YqKw4t3vj+AnBguUYt/x3wObnXN/PmXV+CRoFP/95+Ndt9ninPu8c26Jc245/ro+6Zz7KPAUfsI3CNg5Azjn9gG7zey04qIrgU0E+FoXvQlcbGbJ4n/v4+cd6OtdNNO1fQT4eHG0y8XAwJSumdI45+bVC7gGeB14A/jCXNdnls7xP+G/hv0S2Fh8XYPvU/4xsBV4AmiY67rO0vlfAfxr8f1JwPPANuAfgfhc128WzvdcYH3xev8TUH8iXGvgj4DXgFeAfwDiQbvewPfx9wiy+G9jN890bQHDj+J7A3gZPwLoqI6nR/9FRAJivnW5iIjIDBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGA+P8C0H9Rd2OohgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
